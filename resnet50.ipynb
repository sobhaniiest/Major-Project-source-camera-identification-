{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBGrc2g9mt1IXRCch7jvwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sobhaniiest/Major-Project-source-camera-identification-/blob/master/resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccH_5NHss5u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPQmepHks8Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUeW1wLos-5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout,Activation,Flatten\n",
        "\n",
        "from imagenet_utils import preprocess_input\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI838PJWtEvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Img_size = 512\n",
        "epochs = 25\n",
        "batch_size = 64\n",
        "\n",
        "# Loading the training data\n",
        "# Define data path\n",
        "data_path = '/content/drive/My Drive/FBH'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "\n",
        "img_data_list=[]\n",
        "\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
        "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\tfor img in img_list:\n",
        "\t\timg_path = data_path + '/'+ dataset + '/'+ img \n",
        "\t\timg = image.load_img(img_path, target_size=(Img_size, Img_size))\n",
        "\t\tx = image.img_to_array(img)\n",
        "\t\tx = np.expand_dims(x, axis=0)\n",
        "\t\tx = preprocess_input(x)\n",
        "\t\tprint('Input image shape:', x.shape)\n",
        "\t\timg_data_list.append(x)\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "#img_data = img_data.astype('float32')\n",
        "print (img_data.shape)\n",
        "img_data=np.rollaxis(img_data,1,0)\n",
        "print (img_data.shape)\n",
        "img_data=img_data[0]\n",
        "print (img_data.shape)\n",
        "\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 5\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n",
        "labels[0:150]=0\n",
        "labels[150:300]=1\n",
        "labels[300:450]=2\n",
        "labels[450:600]=3\n",
        "labels[600:]=4\n",
        "\n",
        "\n",
        "# convert class labels to on-hot encoding\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28k5xZCOtKeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVMAq2K5tNko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Custom_resnet_model_1\n",
        "#Training the classifier alone\n",
        "image_input = Input(shape=(Img_size, Img_size, 3))\n",
        "\n",
        "model = ResNet50(input_tensor=image_input, require_flatten=False,weights='imagenet')\n",
        "model.summary()\n",
        "last_layer = model.get_layer('avg_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "out = Dense(num_classes, activation='softmax', name='output_layer')(x)\n",
        "custom_resnet_model = Model(inputs=image_input,outputs= out)\n",
        "custom_resnet_model.summary()\n",
        "\n",
        "for layer in custom_resnet_model.layers[:-1]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "custom_resnet_model.layers[-1].trainable\n",
        "\n",
        "custom_resnet_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "t=time.time()\n",
        "hist = custom_resnet_model.fit(X_train, y_train, batch_size, epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "print('Training time: %s' % (t - time.time()))\n",
        "(loss, accuracy, f1_score, precision, recall) = custom_resnet_model.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%, F1-score={:.4f}, Precision={:.4f}, Recall={:.4f}\".format(loss, accuracy * 100, f1_score, precision, recall))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUnDgcxB-oz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = custom_resnet_model.predict(X_test)\n",
        "print(\"Class\")\n",
        "print(y_test)\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "print('Confusion Matrix')\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmhDa0CItOO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine tune the resnet 50\n",
        "\n",
        "image_input = Input(shape=(Img_size, Img_size, 3))\n",
        "model = ResNet50(input_tensor=image_input, weights='imagenet', require_flatten=False)\n",
        "model.summary()\n",
        "last_layer = model.output\n",
        "# add a global spatial average pooling layer\n",
        "x = GlobalAveragePooling2D()(last_layer)\n",
        "\n",
        "# add fully-connected & dropout layers\n",
        "x = Dense(512, activation='relu',name='fc-1')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu',name='fc-2')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "###\n",
        "#x = Dense(128, activation='relu',name='fc-3')(x)\n",
        "#x = Dropout(0.5)(x)\n",
        "###\n",
        "# a softmax layer for 5 classes\n",
        "out = Dense(num_classes, activation='softmax',name='output_layer')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "custom_resnet_model2 = Model(inputs=model.input, outputs=out)\n",
        "\n",
        "custom_resnet_model2.summary()\n",
        "\n",
        "for layer in custom_resnet_model2.layers[:-6]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "custom_resnet_model2.layers[-1].trainable\n",
        "\n",
        "custom_resnet_model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "t=time.time()\n",
        "hist = custom_resnet_model2.fit(X_train, y_train, batch_size, epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "print('Training time: %s' % (t - time.time()))\n",
        "(loss, accuracy, f1_score, precision, recall) = custom_resnet_model2.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%, F1-score={:.4f}, Precision={:.4f}, Recall={:.4f}\".format(loss, accuracy * 100, f1_score, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FSaPhSitR9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# visualizing losses and accuracy\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['accuracy']\n",
        "val_acc=hist.history['val_accuracy']\n",
        "xc=range(epochs)\n",
        "\n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'],loc=4)\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}